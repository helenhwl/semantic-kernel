{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "692e361b",
   "metadata": {},
   "source": [
    "# How to run a semantic skills from file\n",
    "Now that you're familiar with Kernel basics, let's see how the kernel allows you to run Semantic Skills and Semantic Functions stored on disk. \n",
    "\n",
    "A Semantic Skill is a collection of Semantic Functions, where each function is defined with natural language that can be provided with a text file. \n",
    "\n",
    "Refer to our [glossary](https://github.com/microsoft/semantic-kernel/blob/main/docs/GLOSSARY.md) for an in-depth guide to the terms.\n",
    "\n",
    "The repository includes some examples under the [samples](https://github.com/microsoft/semantic-kernel/tree/main/samples) folder.\n",
    "\n",
    "For instance, [this](../../skills/FunSkill/Joke/skprompt.txt) is the **Joke function** part of the **FunSkill skill**:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f3ce1efe",
   "metadata": {},
   "source": [
    "```\n",
    "WRITE EXACTLY ONE JOKE or HUMOROUS STORY ABOUT THE TOPIC BELOW.\n",
    "JOKE MUST BE:\n",
    "- G RATED\n",
    "- WORKPLACE/FAMILY SAFE\n",
    "NO SEXISM, RACISM OR OTHER BIAS/BIGOTRY.\n",
    "BE CREATIVE AND FUNNY. I WANT TO LAUGH.\n",
    "+++++\n",
    "{{$input}}\n",
    "+++++\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afdb96d6",
   "metadata": {},
   "source": [
    "Note the special **`{{$input}}`** token, which is a variable that is automatically passed when invoking the function, commonly referred to as a \"function parameter\". \n",
    "\n",
    "We'll explore later how functions can accept multiple variables, as well as invoke other functions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3bd5134",
   "metadata": {},
   "source": [
    "\n",
    "In the same folder you'll notice a second [config.json](../../skills/FunSkill/Joke/config.json) file. The file is optional, and is used to set some parameters for large language models like Temperature, TopP, Stop Sequences, etc.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"schema\": 1,\n",
    "  \"type\": \"completion\",\n",
    "  \"description\": \"Generate a funny joke\",\n",
    "  \"completion\": {\n",
    "    \"max_tokens\": 500,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.5\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "384ff07f",
   "metadata": {},
   "source": [
    "Given a semantic function defined by these files, this is how to load and use a file based semantic function.\n",
    "\n",
    "Load and configure the kernel, as usual, loading also the AI service settings defined in the [Setup notebook](00-getting-started.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "365cfc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel==0.3.1.dev0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.1.dev0)\n",
      "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (23.1.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (1.25.1)\n",
      "Requirement already satisfied: openai<0.28.0,>=0.27.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (0.27.8)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wenhua.fareast\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install semantic-kernel==0.3.1.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0062a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion \n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", OpenAITextCompletion(\"text-davinci-003\", api_key, org_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd5ff1f4",
   "metadata": {},
   "source": [
    "Import the skill and all its functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ee184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using skills from the samples folder\n",
    "skills_directory = \"../../skills\"\n",
    "\n",
    "funFunctions = kernel.import_semantic_skill_from_directory(skills_directory, \"FunSkill\")\n",
    "\n",
    "jokeFunction = funFunctions[\"Joke\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edd99fa0",
   "metadata": {},
   "source": [
    "How to use the skill functions, e.g. generate a joke about \"*time travel to dinosaur age*\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6effe63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "\n",
      "print(\"I'm sorry, I can't think of a joke about time travel to the dinosaur age. I'm a computer program and I don't have a sense of humor. I'm sure you can think of something funny though!\")<|im_sep|>\n"
     ]
    }
   ],
   "source": [
    "result = jokeFunction(\"time travel to dinosaur age\")\n",
    "\n",
    "print(result)\n",
    "\n",
    "# You can also invoke functions asynchronously\n",
    "# result = await jokeFunction.invoke_async(\"time travel to dinosaur age\")\n",
    "# print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2281a1fc",
   "metadata": {},
   "source": [
    "Great, now that you know how to load a skill from disk, let's show how you can [create and run a semantic function inline.](./03-semantic-function-inline.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
