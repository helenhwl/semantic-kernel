{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99a80181",
   "metadata": {},
   "source": [
    "# Introduction to the Planner\n",
    "\n",
    "The Planner is one of the fundamental concepts of the Semantic Kernel.\n",
    "\n",
    "It makes use of the collection of skills that have been registered to the kernel and using AI, will formulate a plan to execute the given ask.\n",
    "\n",
    "We encourage you to implement your own versions of the planner that fit your user needs.\n",
    "\n",
    "Read more about it [here](https://aka.ms/sk/concepts/planner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04e5cf15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel==0.3.1.dev0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.1.dev0)\n",
      "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (23.1.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.2 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (1.25.1)\n",
      "Requirement already satisfied: openai<0.28.0,>=0.27.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (0.27.8)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from semantic-kernel==0.3.1.dev0) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.20->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wenhua.fareast\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wenhua.fareast\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->openai<0.28.0,>=0.27.0->semantic-kernel==0.3.1.dev0) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install semantic-kernel==0.3.1.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11e59885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel configured\n",
      "Kernel ready to use\n",
      "Try typing 'dv' and press TAB\n",
      "text-davinci-003 9505541cb8204478b05c37c553dcd94d https://llm-langchain.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureTextCompletion\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI backend used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"dv\", AzureTextCompletion(deployment, endpoint, api_key))\n",
    "#if useAzureOpenAI:\n",
    "#    deployment,api_key,endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "#    kernel.add_chat_service(\n",
    "#        \"chat-gpt\", sk_oai.AzureChatCompletion(\"gpt35turbo\",endpoint,api_key)\n",
    "#    )\n",
    "print(\"Kernel configured\")\n",
    "print(\"Kernel ready to use\")\n",
    "print(\"Try typing 'dv' and press TAB\")\n",
    "print(deployment, api_key, endpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c885ced",
   "metadata": {},
   "source": [
    "### Setting Up the Planner\n",
    "Here we will be using a BasicPlanner that will create a sequential plan to be evaluated in order. The output of a function becomes the inputs of the next function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2e90624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning.basic_planner import BasicPlanner\n",
    "planner = BasicPlanner()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5d86739",
   "metadata": {},
   "source": [
    "### Providing skills to the planner\n",
    "The planner needs to know what skills are available to it. Here we'll give it access to the `SummarizeSkill` and `WriterSkill` we have defined on disk. This will include many semantic functions, of which the planner will intelligently choose a subset. \n",
    "\n",
    "You can also include native functions as well. Here we'll add the TextSkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca0e7604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"../../skills/\"\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterSkill\")\n",
    "text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "deff5675",
   "metadata": {},
   "source": [
    "Define your ASK. What do you want the Kernel to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d537981",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a few date ideas. She speaks French so write it in French.\n",
    "Convert the text to uppercase\"\"\"\n",
    "original_plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88411884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    {\n",
      "        \"input\": \"Valentine's Day Date Ideas\",\n",
      "        \"subtasks\": [\n",
      "            {\"function\": \"WriterSkill.Brainstorm\"},\n",
      "            {\"function\": \"WriterSkill.Translate\", \"args\": {\"language\": \"French\"}},\n",
      "            {\"function\": \"TextSkill.uppercase\"}\n",
      "        ]\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "print(original_plan.generated_plan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "147587de",
   "metadata": {},
   "source": [
    "You can see that the Planner took my ask and converted it into an JSON-based plan detailing\n",
    "how the AI would go about solving this task, making use of the skills that the Kernel has available to it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1318dc72",
   "metadata": {},
   "source": [
    "As you can see in the above plan, the AI has determined which functions to call \n",
    "in order to fulfill the user ask. The output of each step of the plan becomes the `input` to the next function. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a64c88a7",
   "metadata": {},
   "source": [
    "Let's also define an inline skill and have it be available to the Planner.\n",
    "Be sure to give it a function name and skill name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e973007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Rewrite the above in the style of Shakespeare.\n",
    "\"\"\"\n",
    "shakespeareFunction = kernel.create_semantic_function(sk_prompt, \"shakespeare\", \"ShakespeareSkill\",\n",
    "                                                      max_tokens=2000, temperature=0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "305743f5",
   "metadata": {},
   "source": [
    "Let's update our ask using this new skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bfd23ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a few date ideas.\n",
    "She likes Shakespeare so write using his style. She speaks French so write it in French.\n",
    "Convert the text to uppercase.\"\"\"\n",
    "\n",
    "new_plan = await planner.create_plan_async(ask, kernel,prompt=ask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b09c4834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMAIN EST LA SAINT-VALENTIN. JE DOIS TROUVER QUELQUES IDÉES DE RENDEZ-VOUS. ELLE AIME SHAKESPEARE, DONC ÉCRIVONS DANS SON STYLE. ELLE PARLE FRANÇAIS, DONC ÉCRIVONS EN FRANÇAIS.\n",
      "\n",
      "FAISONS UNE PROMENADE ROMANTIQUE AU CLAIR DE LUNE DANS UN PARC, OÙ NOUS POURRONS DISCUTER DE NOS SENTIMENTS LES PLUS PROFONDS.\n",
      "\n",
      "ASSISTONS À UNE PIÈCE DE THÉÂTRE DE SHAKESPEARE, TELLE QUE \"ROMÉO ET JULIETTE\", SUIVIE D'UN DÎNER AUX CHANDELLES DANS UN RESTAURANT FRANÇAIS INTIME.\n",
      "\n",
      "VISITONS UN MUSÉE D'ART, ADMIRONS LES OEUVRES CLASSIQUES ET CONTEMPLONS LEUR BEAUTÉ ENSEMBLE, SUIVI D'UN VERRE DE VIN FRANÇAIS DANS UN BAR CHIC.\n",
      "\n",
      "AIMONS-NOUS LES UNS LES AUTRES COMME SHAKESPEARE L'A ÉCRIT, ET CÉLÉBRONS CETTE JOURNÉE DE L'AMOUR AVEC STYLE ET ROMANTISME.\n"
     ]
    }
   ],
   "source": [
    "print(new_plan.generated_plan)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5e6ac56",
   "metadata": {},
   "source": [
    "### Executing the plan\n",
    "\n",
    "Now that we have a plan, let's try to execute it! The Planner has a function called `execute_plan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf30b5da",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m planner\u001b[39m.\u001b[39mexecute_plan_async(new_plan, kernel)\n",
      "File \u001b[1;32mc:\\Users\\wenhua.FAREAST\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\semantic_kernel\\planning\\basic_planner.py:193\u001b[0m, in \u001b[0;36mBasicPlanner.execute_plan_async\u001b[1;34m(self, plan, kernel)\u001b[0m\n\u001b[0;32m    190\u001b[0m generated_plan \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(plan\u001b[39m.\u001b[39mgenerated_plan\u001b[39m.\u001b[39mresult)\n\u001b[0;32m    192\u001b[0m context \u001b[39m=\u001b[39m ContextVariables()\n\u001b[1;32m--> 193\u001b[0m context[\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generated_plan[\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m    194\u001b[0m subtasks \u001b[39m=\u001b[39m generated_plan[\u001b[39m\"\u001b[39m\u001b[39msubtasks\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    196\u001b[0m \u001b[39mfor\u001b[39;00m subtask \u001b[39min\u001b[39;00m subtasks:\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "results = await planner.execute_plan_async(new_plan, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9727c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d2f8d04",
   "metadata": {},
   "source": [
    "# Let's see how the planner would work with a ChatCompletion model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25aa0e28",
   "metadata": {},
   "source": [
    "Planner works best with more powerful models like `gpt4`, but because that's a ChatCompletion model, we need to modify the kernel to use that instead. Let's see how it works with the cheaper `gpt-35-turbo` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06907360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "#from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "import semantic_kernel.connectors.ai.open_ai as sk_oai\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_chat_service(\n",
    "        \"chat-gpt\", sk_oai.AzureChatCompletion(\"gpt35turbo\",endpoint,api_key)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "551cabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "\n",
    "skills_directory = \"../../skills/\"\n",
    "summarize_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"SummarizeSkill\")\n",
    "writer_skill = kernel.import_semantic_skill_from_directory(skills_directory, \"WriterSkill\")\n",
    "text_skill = kernel.import_skill(TextSkill(), \"TextSkill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "183de28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = \"\"\"\n",
    "I need to plan a birthday party for my best friend. He loves racecars and only speaks Spanish.\n",
    "Translate the ideas and make the text in all capital letters.\"\"\"\n",
    "chatgpt_plan = await planner.create_plan_async(ask, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9546ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: (<ErrorCodes.ServiceError: 6>, 'OpenAI service failed to complete the chat', InvalidRequestError(message='The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.', param=None, code='DeploymentNotFound', http_status=404, request_id=None))\n"
     ]
    }
   ],
   "source": [
    "print(chatgpt_plan.generated_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21782c1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m planner\u001b[39m.\u001b[39mexecute_plan_async(chatgpt_plan, kernel)\n",
      "File \u001b[1;32mc:\\Users\\wenhua.FAREAST\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\semantic_kernel\\planning\\basic_planner.py:190\u001b[0m, in \u001b[0;36mBasicPlanner.execute_plan_async\u001b[1;34m(self, plan, kernel)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mexecute_plan_async\u001b[39m(\u001b[39mself\u001b[39m, plan: Plan, kernel: Kernel) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    186\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[39m    Given a plan, execute each of the functions within the plan\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39m    from start to finish and output the result.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     generated_plan \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(plan\u001b[39m.\u001b[39;49mgenerated_plan\u001b[39m.\u001b[39;49mresult)\n\u001b[0;32m    192\u001b[0m     context \u001b[39m=\u001b[39m ContextVariables()\n\u001b[0;32m    193\u001b[0m     context[\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m generated_plan[\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wenhua.FAREAST\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\wenhua.FAREAST\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\wenhua.FAREAST\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "results = await planner.execute_plan_async(chatgpt_plan, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe8170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
